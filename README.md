# Income Tax QA System using Retrieval-Augmented Generation (RAG) with Mistral 7B

This project implements a **Retrieval-Augmented Generation (RAG)** pipeline that allows users to query legal documentsâ€”like *The Income Tax Act, 1961*â€”and receive natural language answers. The system combines the power of semantic retrieval and generative language models to answer user queries with high relevance and contextual awareness.

---

## ğŸš€ Features

- ğŸ’¬ Question Answering on Legal PDFs  
- ğŸ” Semantic Search using all-MiniLM-L6-v2 embeddings  
- ğŸ§  Context-aware generation using Mistral 7B (via Hugging Face)  
- ğŸ§¾ PDF ingestion and intelligent chunking for vectorization  
- âš¡ High-speed retrieval with ChromaDB Vector Store

---

## ğŸ› ï¸ Tech Stack

- Python
- LangChain
- Hugging Face Transformers
- Sentence Transformers
- Chroma Vector Store
- PyTorch
- PyPDFLoader

---

## ğŸ“‚ Project Workflow

1. Load and parse PDF using PyPDFLoader
2. Split text into manageable chunks using CharacterTextSplitter
3. Generate vector embeddings using all-MiniLM-L6-v2
4. Store vectors in ChromaDB for efficient retrieval
5. Accept user questions and retrieve top relevant chunks
6. Use Mistral 7B to generate natural language answers

---

## âš™ï¸ Setup Instructions

### 1. Clone Repository and Install Dependencies

```bash
pip install langchain langchain_community sentence-transformers chromadb torch torchvision torchaudio transformers accelerate pypdf
